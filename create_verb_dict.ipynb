{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "# stanza.download('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 13:44:08 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2020-07-31 13:44:08 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-07-31 13:44:08 INFO: Use device: cpu\n",
      "2020-07-31 13:44:08 INFO: Loading: tokenize\n",
      "2020-07-31 13:44:08 INFO: Loading: pos\n",
      "2020-07-31 13:44:09 INFO: Loading: lemma\n",
      "2020-07-31 13:44:09 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# # unlemmatized\n",
    "# data = pd.read_csv(\"../data/flattened_paragraphs.csv\", index_col=None)\n",
    "# lemmatized\n",
    "data = pd.read_csv(\"data/flattened_paragraphs.csv\", index_col=None)\n",
    "raw_sentences = data[\"sentence\"].to_list()\n",
    "# stanza.download('en')\n",
    "sentence_id = data[\"sentence ID\"].to_list()\n",
    "paragraph_id = data[\"paragraphID\"].to_list()\n",
    "\n",
    "verb_dict = {}\n",
    "# for sentence in sentences:\n",
    "all_words_dict = {}\n",
    "# for storing each type of word\n",
    "pos_dict = {}\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_verbs = []\n",
    "\n",
    "l = len(raw_sentences)\n",
    "i = 0\n",
    "for s in raw_sentences:\n",
    "#     print(i/l)\n",
    "    doc = nlp(s)\n",
    "    for sent in doc.sentences:\n",
    "#         print(s)\n",
    "        for word in sent.words:\n",
    "            # check the type of the word\n",
    "            if str(word.upos) == \"VERB\":\n",
    "                \n",
    "                lemmatized_word = word.lemma\n",
    "                if lemmatized_word not in unique_verbs:\n",
    "                    unique_verbs.append(lemmatized_word)\n",
    "                \n",
    "                text = word.text.lower()\n",
    "                if text not in pos_dict:\n",
    "                    # create the term for the word, add the sentence.\n",
    "                    pos_dict[text] = {str(paragraph_id[i])+\", \"+str(sentence_id[i]): s}\n",
    "                else:\n",
    "                    pos_dict[text][str(paragraph_id[i])+\", \"+str(sentence_id[i])] = s\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/stanza_verbs.json\", 'w') as file:\n",
    "    json_string = json.dumps(pos_dict,sort_keys=True, indent=4)\n",
    "    file.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_verbs_lowered = []\n",
    "for v in unique_verbs:\n",
    "    unique_verbs_lowered.append(v.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_verbs = sorted(unique_verbs_lowered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_verbs = sorted(unique_verbs_lowered)\n",
    "unique_verbs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
